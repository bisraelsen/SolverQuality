\documentclass[sigconf,authordraft]{acmart}

\usepackage{pgfgantt}
\usepackage{booktabs}
\usepackage{graphicx,caption}
\usepackage{mathtools}%loads amsmath
\usepackage{amssymb,amsfonts}
% \usepackage[caption=false]{subfig}
% \captionsetup{width=\textwidth}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[margin=0.75in]{geometry}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[FAT* 2019]{Conference on Fairness, Accountability, and Tranparency}{January 2019}{Atlanta, Georgia USA}
\acmYear{2019}
\copyrightyear{2019}

\acmPrice{15.00}

\acmSubmissionID{123-A12-B3}

%%%%% shortcut commands
\newcommand{\solve}{$\mathcal{S}$}
\newcommand{\solvestar}{$\mathcal{S}^*$}
\newcommand{\task}{$\mathcal{T}$}
\newcommand{\taski}{$\mathcal{T}_i$}
\newcommand{\taskN}{$\mathcal{T}_N$}
\newcommand{\rwd}{$\mathcal{R}$}
\newcommand{\rwdstar}{$\mathcal{R}^*$}
\newcommand{\rwdstari}{$\mathcal{R}^*_i$}
\newcommand{\rwdstarN}{$\mathcal{R}^*_N$}
\newcommand{\rwdstarapprox}{$\widetilde{\mathcal{R}}^*$}
\newcommand{\rwdstariapprox}{$\widetilde{\mathcal{R}}^*_i$}
\newcommand{\policy}{$\mathcal{\pi}$}
\newcommand{\policystar}{$\mathcal{\pi}^*$}
\newcommand{\surrogate}{$\mathcal{M}^*(\mathcal{T})$}
\newcommand{\xQ}{$x_Q$}
\newcommand{\xP}{$x_P$}
\newcommand{\xH}{$x_H$}
\newcommand{\xI}{$x_I$}
\newcommand{\xM}{$x_M$}
%%%%%%%%%%

\begin{document}

\title{``I've got just the tool for the job\ldots''}
\subtitle{Meta-analysis of Decision Making for Transparency}
\author{Author 1}
    \orcid{0000-0000-0000-0000}
    \email{ano.ny@mous.com}
\author{Author 2}
    \affiliation{%
        \institution{Prestigious Institution}
        \city{city}
        \state{state}
        \country{country}
    }
\begin{abstract}
    Humans need to be able to appropriately trust autonomous systems before they can appropriately use them, but they cannot trust something that they don't understand to some extent. It is possible for robots to influence a user's trust via `algorithmic assurances'. Here one such assurance is discussed in the context of Markov decision processes. Markov decision processes underlie much of the theory of reinforcement learning, and are commonly used for planning and decision making in robotics. However, it is challenging for human users to understand the limitations of these systems. There are several `meta properties' of Markov decision processes that can help human users to accurately assess the robot's competency in different situations. Herein, one of those properties, called `solver quality', is presented as one useful way by which humans can be assured of a robot's competency. Several trials demonstrate that the metric exhibits desirable properties to be used as an algorithmic assurance.
\end{abstract}
\maketitle

\input{"introduction.tex"}
\input{"methodology.tex"}
\input{"results.tex"}
\input{"conclusions.tex"}

\bibliographystyle{ACM-Reference-Format}
\bibliography{References}

\end{document}
